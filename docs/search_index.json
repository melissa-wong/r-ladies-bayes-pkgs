[["index.html", "Intro to R Bayes Packages Preface", " Intro to R Bayes Packages Melissa Wong 2021-01-02 Preface My motivation for this presentation was to put together the “Intro to R packages for Bayesian models” information I wish had gotten in the Intro to Bayes course I took in grad school. During that course, we learned some of the underlying theory, spent a lot of time on conjugate priors and deriving posterior distributions by hand, and implemented some sampling algorithms. All great things to learn! However, after the class was over I didn’t feel like I could actually use what I learned in practice. It just seemed silly to me to think I would write a custom sampler every time when there are existing software packages that use better, faster sampling algorithms than what we covered in class. So then the question became which software package should I use and why? This presentation summarizes what I learned by experimenting with several different packages in the process of answering that question for myself. Hopefully the information that follows will also help you figure out which path is easiest for you to start using Bayesian methods. "],["intro.html", "Chapter 1 Introduction 1.1 Resources 1.2 A Motivating Example 1.3 Workflow 1.4 Data 1.5 Prior Information", " Chapter 1 Introduction 1.1 Resources Bayesian Data Analysis by Andrew Gelman, et. al. A First Course in Bayesian Statistical Methods by Peter Hoff Statistical Rethinking by Richard McElreath 1.2 A Motivating Example Let’s start with something familiar–the Monty Hall problem. There are three doors labeled A, B and C. A car is behind one of the doors and a goat is behind each of the other two doors. You choose a door (let’s say A). Monty Hall, who knows where the car actually is, opens one of the other doors (let’s say B) revealing a goat. Do you stay with door A or do you switch to door C? We can frame the problem as follows: Initially, you believe the car is equally likely to behind each door (i.e., \\(P[A=car]=P[B=car]=P[C=car]=\\frac{1}{3}\\)). Let’s call this the prior information. Next, you can calculate the conditional probabilities that Monty Hall opened door B. Let’s call this the likelihood. \\[\\begin{align*} P[B=open | A=car] &amp;= \\frac{1}{2}\\\\ P[B=open | B=car] &amp;= 0 \\\\ P[B=open | C=car] &amp;=1 \\end{align*}\\] Finally, you can update your beliefs with the new information. Let’s call your updated beliefs the posterior. \\[\\begin{align*} P[A=car|B=open] &amp;= \\frac{P[B=open|A=car]P[A=car]}{P[B=open]} = \\frac{1/2 * 1/3}{1/6 + 0 + 1/3} = \\frac{1}{3} \\\\ P[B=car|B=open] &amp;= \\frac{P[B=open|B=car]P[B=car]}{P[B=open]} = \\frac{0 * 1/3}{1/6 + 0 + 1/3} = 0 \\\\ P[C=car|B=open] &amp;= \\frac{P[B=open|C=car]P[C=car]}{P[B=open]} = \\frac{1 * 1/3}{1/6 + 0 + 1/3} = \\frac{2}{3} \\end{align*}\\] Clearly, you should switch to door C. This is a toy illustration of how to think about a model in a Bayesian framework: \\[posterior \\propto likelihood * prior\\] (See the resources for a proper mathematical derivation.) 1.3 Workflow The workflow I’ll follow in the subsequent chapters is as follows: Define the model. Examine the prior predictive distribution. Examine diagnostic plots. Examine posterior distribution. Examine the posterior predictive distribution. In general, this is an iterative process. At each step you may discover something that causes you to start over at step 1 with a new, refined model. 1.4 Data For all of the examples, I use the mtcars data set and a model with mean centered disp as the predictor and mpg as the response. I start with a simple linear regression. However, as you can see from the scatterplot below, the relationship between mpg and disp is not linear, so I also fit a slightly more complex semi-parametric model. There are two reasons why I use mean centered disp: Interpretation of the intercept is the average mpg at the average value of displacement versus average mpg at zero displacement (which has little practical meaning). Several of the packages used in the examples assume priors are for mean-centered predictors for sampling efficiency. I use the bayesplot package to demonstrate the steps for creating some of the most common diagnostic plots. I found this helpful as I was learning how to use each package. The tidybayes package is another good option for visualization of Bayesian models. However, I highly recommend the shinystan package; it will automatically create all of these diagnostic plots (and more) with an nice interactive web interface. library(tidyverse) library(datasets) data(mtcars) mtcars %&gt;% ggplot(aes(x=disp, y=mpg)) + geom_point() 1.5 Prior Information The mtcars dataset was extracted for Motor Trend magazine data on 1973-1974 models. The 1974 EPA Car Mileage Guide lists the mpg and engine size (i.e displacement) for U.S. cars and light duty trucks. The data is plotted below. library(gridExtra) library(here) epa &lt;- read.csv(here(&quot;data&quot;, &quot;EPA_1974.csv&quot;), header=TRUE) p1 &lt;- ggplot() + geom_histogram(data=epa, mapping=aes(x=mpg), binwidth = 1) p2 &lt;- ggplot(epa) + geom_histogram(mapping=aes(x=Displacement), binwidth=20) p3 &lt;- ggplot(epa) + geom_point(mapping=aes(x=Displacement, y=mpg)) grid.arrange(p1, p2, ncol=2) p3 "],["rstanarm.html", "Chapter 2 rstanarm 2.1 Resources 2.2 Description 2.3 Environment Setup 2.4 Linear Model (Default Priors) 2.5 Linear Model (User-Defined Priors) 2.6 Semi-parametric Model 2.7 Session Info", " Chapter 2 rstanarm 2.1 Resources Regression and Other Stories by Gelman, Hill and Vehtari rstanarm online documentation User-friendly Bayesian regression modeling: A tutorial with rstanarm and shinystan by Muth, Oravecz and Gabry 2.2 Description The rstanarm package is one of the easiest ways to get started with Bayesian models. The functions parallel the frequentist functions you’re probably already familiar with, and the syntax will also be familiar. You aren’t required to explicitly choose priors because all of the functions have weakly informative priors by default (although some might argue not being required to specify priors is a drawback). The primary limitation I’ve found thus far is the supported types for user-defined priors is somewhat limited. 2.3 Environment Setup set.seed(123) options(&quot;scipen&quot; = 1, &quot;digits&quot; = 4) library(tidyverse) library(gridExtra) library(kableExtra) library(datasets) data(mtcars) # mean center disp predictor mtcars$c_disp = mtcars$disp - mean(mtcars$disp) library(rstanarm) library(bayesplot) # Set number of cores options(mc.cores = parallel::detectCores()) 2.4 Linear Model (Default Priors) 2.4.1 Define Model Let’s start with the following simple linear model: \\[\\begin{align*} mpg &amp;\\sim Normal(\\mu, \\sigma^2) \\\\ \\mu &amp;= a + b*c\\_disp \\\\ \\end{align*}\\] The stan_glm function from the rstanarm package fits a Bayesian linear model. The syntax is very similar to lm/glm. mdl1 &lt;- stan_glm(mpg ~ c_disp, data = mtcars) 2.4.2 Prior Predictive Distribution Next, I’ll examine the prior predictive distribution to see if the default priors seem reasonable. The prior_summary function shows the default priors for the model as well as the adjusted priors after automatic scaling. See http://mc-stan.org/rstanarm/articles/priors.html if you are interested in the details about how the default and adjusted priors are calculated. prior_summary(mdl1) ## Priors for model &#39;mdl1&#39; ## ------ ## Intercept (after predictors centered) ## Specified prior: ## ~ normal(location = 20, scale = 2.5) ## Adjusted prior: ## ~ normal(location = 20, scale = 15) ## ## Coefficients ## Specified prior: ## ~ normal(location = 0, scale = 2.5) ## Adjusted prior: ## ~ normal(location = 0, scale = 0.12) ## ## Auxiliary (sigma) ## Specified prior: ## ~ exponential(rate = 1) ## Adjusted prior: ## ~ exponential(rate = 0.17) ## ------ ## See help(&#39;prior_summary.stanreg&#39;) for more details Overlaying the default prior for the intercept with the EPA data gives a sense of what a weakly informative prior for this data looks like. # Plot expected value of prior predictive distribution using adjusted priors N &lt;- 100 prior_samples &lt;- data.frame(a = rnorm(N, 20, 15), b = rnorm(N, 0, 0.12)) D &lt;- seq(min(mtcars$c_disp), max(mtcars$c_disp), length.out = N) res &lt;- as.data.frame(apply(prior_samples, 1, function(x) x[1] + x[2] * (D))) %&gt;% mutate(c_disp = D) %&gt;% pivot_longer(cols=-c_disp, names_to=&quot;iter&quot;) (default_prior_plot &lt;- res %&gt;% ggplot() + geom_line(aes(x=c_disp, y=value, group=iter), alpha=0.2) + labs(x=&quot;c_disp&quot;, y=&quot;mpg&quot;, title = &quot;Prior Predictive Distribution - Default Priors&quot;)) I notice two things in the prior predictive distribution which seem unrealistic given what I know about the real world: plausibility of 1) negative mpg and 2) increasing mpg as displacement increases. Later on I’ll choose a more informative prior which incorporates this external knowledge. But let’s proceed with the analysis and see what happens. 2.4.3 Diagnostics 2.4.3.1 Trace Plots The bayesplot package provides the function mcmc_trace which plots the Markov Chain Monte Carlo (MCMC) draws. mcmc_trace(mdl1) There are three things I am looking for in the trace plot of each chain: Good mixing - In other words, the chain is rapidly changing values across the full region versus getting “stuck” near a particular value and slowly changing. Stationarity - The mean of the chain is relatively stable. Convergence - All of the chains spend most of the time around the same high-probability value. 2.4.3.2 Trace Rank Plots It can sometimes be hard to interpret the trace plots when there are many chains. An alternative is the mcmc_rank_overlay function. This function plots a trace rank plot which is the distribution of the ranked samples; if the four chains have a roughly uniform distribution that indicates good mixing. mcmc_rank_overlay(mdl1) The chains look good based on the plots above. 2.4.3.3 \\(\\widehat{R}\\) and Effective Sample Size In addition to visually examining the chains, we should also check \\(\\widehat{R}\\) which is a measure of convergence. \\(\\widehat{R} &gt; 1.0\\) indicates poor mixing, and the mc_stan documentation recommends only using samples if \\(\\widehat{R} &lt; 1.05\\). However, a recent paper by Vehtari et al. (2020) recommends \\(\\widehat{R} &lt; 1.01\\). Since MCMC samples are usually correlated, the effective sample size (n_eff) is often less than the number of samples. There is no hard and fast rule for what is an acceptable number for n_eff. McElreath’s guidance is it depends on what you are trying to estimate. If you are interested mostly in the posterior mean, then n_eff = 200 can be enough. But if you are interested in the tails of the distribution and it’s highly skewed then you’ll need n_eff to be much larger. There are two parameters, iter and warmup, which you can adjust in stan_glm if a larger n_eff is needed. The summary function displays n_eff and \\(\\widehat{R}\\) for the object returned by stan_glm. summary(mdl1) ## ## Model Info: ## function: stan_glm ## family: gaussian [identity] ## formula: mpg ~ c_disp ## algorithm: sampling ## sample: 4000 (posterior sample size) ## priors: see help(&#39;prior_summary&#39;) ## observations: 32 ## predictors: 2 ## ## Estimates: ## mean sd 10% 50% 90% ## (Intercept) 20.1 0.6 19.3 20.1 20.9 ## c_disp 0.0 0.0 0.0 0.0 0.0 ## sigma 3.4 0.5 2.8 3.3 4.0 ## ## Fit Diagnostics: ## mean sd 10% 50% 90% ## mean_PPD 20.1 0.9 19.0 20.1 21.2 ## ## The mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help(&#39;summary.stanreg&#39;)). ## ## MCMC diagnostics ## mcse Rhat n_eff ## (Intercept) 0.0 1.0 3147 ## c_disp 0.0 1.0 3328 ## sigma 0.0 1.0 3056 ## mean_PPD 0.0 1.0 3411 ## log-posterior 0.0 1.0 1529 ## ## For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1). 2.4.4 Posterior Distribution Since the chains, n_eff and \\(\\widehat{R}\\) look good, let’s examine the posterior distributions next. The Estimates section of the summary output above displays the posterior point estimates, standard deviation and 10%, 50% and 90% quantiles. Alternatively, we can plot the posterior distributions: # Posterior point estimates (medians are used for point estimates) plot(mdl1) 2.4.5 Posterior Predictive Distribution The posterior_predict function draws samples from the posterior predictive distribution, and then the ppc_dens_overlay function plots the distribution of each draw overlaid with the observed distribution. (mdl1_ppd_plot &lt;- ppc_dens_overlay(mtcars$mpg, posterior_predict(mdl1, draws=50)) + labs(title=&quot;Posterior Predictive Distribution - Default Priors&quot;)) Below I also plot the expected value of the posterior predictive distribution and overlay the observations as an alternative way to visualize the result. The posterior_linpred function returns the linear predictor, possibly transformed by the inverse-link function. The posterior_epred function returns the expectation over the posterior predictive distribution. In this example, the model is a Gaussian likelihood with an identity link function, so the two functions return identical results. newdata &lt;- data.frame(c_disp=seq(min(mtcars$c_disp), max(mtcars$c_disp))) y_rep &lt;- as.data.frame(t(posterior_epred(mdl1, newdata=newdata, draws=50))) %&gt;% cbind(newdata) %&gt;% pivot_longer(cols=starts_with(&quot;V&quot;), names_to=&quot;grp&quot;, values_to=&quot;mpg&quot;) (mdl1_eppd_plot &lt;- y_rep %&gt;% ggplot(aes(x=c_disp, y=mpg)) + geom_line(aes(group=grp), alpha=0.2) + geom_point(data = mtcars) + labs(title=&quot;Expected Value ppd - Default Priors&quot;)) As expected, the linear model is not a good fit to the data. 2.5 Linear Model (User-Defined Priors) I’ll specify priors which incorporate the prior knowledge from the EPA data as well as that mpg is non-negative and is non-increasing as disp increases. My new model is as follows: \\[\\begin{align*} mpg &amp;\\sim Normal(\\mu, \\sigma^2) \\\\ \\mu &amp;= a + b*c\\_disp \\\\ a &amp;\\sim Normal(13.2,5.3^2) \\\\ b &amp;\\sim Normal(-0.1, 0.05^2) \\\\ \\sigma &amp;\\sim Exponential(1) \\end{align*}\\] The differences from the default priors are The intercept prior is now set to the mean and standard deviation from the EPA data (see plot below for comparison to EPA data and default prior). The slope prior is no longer symmetric about 0, but rather it is centered at -0.1 so that positive values are less likely. (A prior distribution such as exponential or log-normal might be preferred in this case; however this is a limitation of rstanarm as those options aren’t available.) 2.5.1 Define Model mdl2 &lt;- stan_glm(mpg ~ c_disp, data = mtcars, prior = normal(-0.1, 0.05), # prior for slope prior_intercept = normal(13.2,5.3), # prior for intercept prior_aux = exponential(1)) # prior for standard deviation 2.5.2 Prior Predictive Distribution Below is an alternative to manually constructing the prior predictive distribution like I did previously. Setting prior_PD = TRUE refits the model without conditioning on the data which then gives the prior predictive distribution. default_prior_plot mdl2_prior &lt;- update(mdl2, prior_PD=TRUE, chains=1) D &lt;- seq(min(mtcars$c_disp), max(mtcars$c_disp), length.out = N) draws &lt;- posterior_epred(mdl2_prior, newdata=data.frame(c_disp=D), draws=50) %&gt;% t() %&gt;% as.data.frame() %&gt;% mutate(c_disp=D) %&gt;% pivot_longer(-c_disp, names_to=&quot;draw&quot;, values_to=&quot;mpg&quot;) draws %&gt;% ggplot() + geom_line(mapping=aes(x=c_disp, y=mpg, group=draw), alpha=0.2) + labs(title=&quot;Prior Predictive Distribution - Informative Priors&quot;) 2.5.3 Diagnostics mcmc_rank_overlay(mdl2) summary(mdl2) ## ## Model Info: ## function: stan_glm ## family: gaussian [identity] ## formula: mpg ~ c_disp ## algorithm: sampling ## sample: 4000 (posterior sample size) ## priors: see help(&#39;prior_summary&#39;) ## observations: 32 ## predictors: 2 ## ## Estimates: ## mean sd 10% 50% 90% ## (Intercept) 20.0 0.6 19.3 20.0 20.8 ## c_disp 0.0 0.0 0.0 0.0 0.0 ## sigma 3.2 0.4 2.7 3.2 3.8 ## ## Fit Diagnostics: ## mean sd 10% 50% 90% ## mean_PPD 20.0 0.8 19.0 20.0 21.1 ## ## The mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help(&#39;summary.stanreg&#39;)). ## ## MCMC diagnostics ## mcse Rhat n_eff ## (Intercept) 0.0 1.0 3530 ## c_disp 0.0 1.0 3908 ## sigma 0.0 1.0 3673 ## mean_PPD 0.0 1.0 4013 ## log-posterior 0.0 1.0 1786 ## ## For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1). The trace rank plots, n_eff and \\(\\widehat{R}\\) all look good. 2.5.4 Posterior Distribution Now let’s compare the posterior with informative versus default priors: # Point estimates knitr::kable(cbind(coef(mdl1), coef(mdl2)), col.names = c(&quot;Default&quot;, &quot;Informative&quot;)) Default Informative (Intercept) 20.111 20.0168 c_disp -0.041 -0.0417 # 95% credible intervals knitr::kable(cbind(posterior_interval(mdl1, prob=0.95), posterior_interval(mdl2, prob=0.95))) %&gt;% add_header_above(c(&quot; &quot; = 1, &quot;Default&quot; = 2, &quot;Informative&quot; = 2)) Default Informative 2.5% 97.5% 2.5% 97.5% (Intercept) 18.9076 21.3009 18.9262 21.1166 c_disp -0.0509 -0.0313 -0.0509 -0.0327 sigma 2.6281 4.3876 2.5380 4.1322 In this case, there is sufficient data that the choice of prior really didn’t make much of a difference. 2.5.5 Posterior Predictive Distribution mdl1_ppd_plot #Equivalent to ppc_dens_overlay(mtcars$mpg, posterior_predict(mdl2, draws=50)) pp_check(mdl2) + labs(title = &quot;Posterior Predictive Distribution - Informative Priors&quot;) (mdl1_eppd_plot) # Expected value of posterior predictive newdata &lt;- data.frame(c_disp=seq(min(mtcars$c_disp), max(mtcars$c_disp))) y_rep &lt;- as.data.frame(t(posterior_epred(mdl2, newdata=newdata, draws=50))) %&gt;% cbind(newdata) %&gt;% pivot_longer(cols=starts_with(&quot;V&quot;), names_to=&quot;grp&quot;, values_to=&quot;mpg&quot;) y_rep %&gt;% ggplot(aes(x=c_disp, y=mpg)) + geom_line(aes(group=grp), alpha=0.2) + geom_point(data = mtcars) + labs(title=&quot;Expected Value ppd - Informative Priors&quot;) The results are very similar to those with the default priors. 2.6 Semi-parametric Model 2.6.1 Define model The linear model is a poor choice for this data, so I’ll try a model with splines next. The stan_gamm4 function from the rstanarm package fits Bayesian nonlinear (and mixed) models. mdl3 &lt;- stan_gamm4(mpg ~ s(c_disp, bs=&quot;cr&quot;, k=7), data = mtcars, adapt_delta = 0.99) 2.6.2 Prior Predictive Distribution Again, I’ll use rstanarm to automatically generate the prior predictive distribution. mdl3_prior &lt;- update(mdl3, prior_PD = TRUE, chains=1) D &lt;- seq(min(mtcars$c_disp), max(mtcars$c_disp), length.out = N) draws &lt;- posterior_epred(mdl3_prior, newdata=data.frame(c_disp=D), draws=50) %&gt;% t() %&gt;% as.data.frame() %&gt;% mutate(c_disp=D) %&gt;% pivot_longer(-c_disp, names_to=&quot;draw&quot;, values_to=&quot;mpg&quot;) draws %&gt;% ggplot(mapping=aes(x=c_disp, y=mpg)) + geom_line(mapping=aes(group=draw), alpha=0.2) + geom_point(data=mtcars, color=&quot;blue&quot;) This prior predictive distribution gives us some crazy possibilities. However we saw earlier that there is enough data that the model isn’t very sensitive to the choice of prior, so let’s continue and see what happens. 2.6.3 Diagnostics and Posterior mcmc_rank_overlay(mdl3) summary(mdl3) ## ## Model Info: ## function: stan_gamm4 ## family: gaussian [identity] ## formula: mpg ~ s(c_disp, bs = &quot;cr&quot;, k = 7) ## algorithm: sampling ## sample: 4000 (posterior sample size) ## priors: see help(&#39;prior_summary&#39;) ## observations: 32 ## ## Estimates: ## mean sd 10% 50% 90% ## (Intercept) 20.1 0.4 19.6 20.1 20.6 ## s(c_disp).1 0.2 1.3 -1.2 0.1 1.6 ## s(c_disp).2 -0.9 1.1 -2.4 -0.8 0.3 ## s(c_disp).3 0.0 0.6 -0.7 0.0 0.7 ## s(c_disp).4 1.2 0.4 0.7 1.2 1.6 ## s(c_disp).5 0.4 0.1 0.2 0.4 0.6 ## s(c_disp).6 -3.1 0.3 -3.5 -3.1 -2.8 ## sigma 2.4 0.3 2.0 2.4 2.8 ## smooth_sd[s(c_disp)1] 1.2 0.7 0.6 1.0 2.0 ## smooth_sd[s(c_disp)2] 3.6 2.0 1.7 3.1 6.2 ## ## Fit Diagnostics: ## mean sd 10% 50% 90% ## mean_PPD 20.1 0.6 19.3 20.1 20.8 ## ## The mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help(&#39;summary.stanreg&#39;)). ## ## MCMC diagnostics ## mcse Rhat n_eff ## (Intercept) 0.0 1.0 3679 ## s(c_disp).1 0.0 1.0 3070 ## s(c_disp).2 0.0 1.0 2407 ## s(c_disp).3 0.0 1.0 4416 ## s(c_disp).4 0.0 1.0 3291 ## s(c_disp).5 0.0 1.0 4717 ## s(c_disp).6 0.0 1.0 3908 ## sigma 0.0 1.0 2538 ## smooth_sd[s(c_disp)1] 0.0 1.0 1350 ## smooth_sd[s(c_disp)2] 0.0 1.0 2234 ## mean_PPD 0.0 1.0 3737 ## log-posterior 0.1 1.0 933 ## ## For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1). The chains, n_eff and \\(\\widehat{R}\\) look good. In the Estimates section above, we also see the posteriors for the model parameters; there isn’t an intuitive interpretation of the spline coefficients so I’ll skip ahead to the posterior predictive distribution. 2.6.4 Posterior Predictive Distribution ppc_dens_overlay(mtcars$mpg, posterior_predict(mdl3, draws=50)) The expectation over the ppd is plotted below, along with a loess curve for comparison. This model is a better fit to the data than the linear model but there is still room for improvement. For example, it looks like the number of cylinders (cyl) would be a useful predictor to include in the model. plot_nonlinear(mdl3, prob=0.95) + geom_point(mapping=aes(x=c_disp, y=mpg-mean(mpg), color=factor(cyl)), data=mtcars) + labs(title=&quot;GAM&quot;, x=&quot;disp-mean(disp)&quot;, y=&quot;mpg-mean(mpg)&quot;) ggplot(mapping=aes(x=c_disp, y=mpg-mean(mpg)), data=mtcars) + geom_point()+ stat_smooth(method=&quot;loess&quot;, level=0.95) + labs(title=&quot;LOESS&quot;) 2.7 Session Info sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Big Sur 10.16 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices datasets utils methods base ## ## other attached packages: ## [1] here_1.0.1 bayesplot_1.7.2 rstanarm_2.21.1 Rcpp_1.0.5 ## [5] kableExtra_1.3.1 gridExtra_2.3 forcats_0.5.0 stringr_1.4.0 ## [9] dplyr_1.0.2 purrr_0.3.4 readr_1.4.0 tidyr_1.1.2 ## [13] tibble_3.0.4 ggplot2_3.3.2 tidyverse_1.3.0 ## ## loaded via a namespace (and not attached): ## [1] minqa_1.2.4 colorspace_2.0-0 ellipsis_0.3.1 ## [4] ggridges_0.5.2 rprojroot_2.0.2 rsconnect_0.8.16 ## [7] markdown_1.1 base64enc_0.1-3 fs_1.5.0 ## [10] rstudioapi_0.13 farver_2.0.3 rstan_2.21.2 ## [13] DT_0.16 fansi_0.4.1 lubridate_1.7.9.2 ## [16] xml2_1.3.2 splines_4.0.3 codetools_0.2-16 ## [19] knitr_1.30 shinythemes_1.1.2 jsonlite_1.7.1 ## [22] nloptr_1.2.2.2 broom_0.7.2 dbplyr_2.0.0 ## [25] shiny_1.5.0 compiler_4.0.3 httr_1.4.2 ## [28] backports_1.2.0 Matrix_1.2-18 assertthat_0.2.1 ## [31] fastmap_1.0.1 cli_2.2.0 later_1.1.0.1 ## [34] htmltools_0.5.0 prettyunits_1.1.1 tools_4.0.3 ## [37] igraph_1.2.6 gtable_0.3.0 glue_1.4.2 ## [40] reshape2_1.4.4 V8_3.4.0 cellranger_1.1.0 ## [43] vctrs_0.3.5 nlme_3.1-149 crosstalk_1.1.0.1 ## [46] xfun_0.19 ps_1.4.0 lme4_1.1-26 ## [49] rvest_0.3.6 mime_0.9 miniUI_0.1.1.1 ## [52] lifecycle_0.2.0 renv_0.12.0 gtools_3.8.2 ## [55] statmod_1.4.35 MASS_7.3-53 zoo_1.8-8 ## [58] scales_1.1.1 colourpicker_1.1.0 hms_0.5.3 ## [61] promises_1.1.1 parallel_4.0.3 inline_0.3.17 ## [64] shinystan_2.5.0 yaml_2.2.1 curl_4.3 ## [67] loo_2.3.1 StanHeaders_2.21.0-6 stringi_1.5.3 ## [70] highr_0.8 dygraphs_1.1.1.6 boot_1.3-25 ## [73] pkgbuild_1.1.0 rlang_0.4.9 pkgconfig_2.0.3 ## [76] matrixStats_0.57.0 evaluate_0.14 lattice_0.20-41 ## [79] labeling_0.4.2 rstantools_2.1.1 htmlwidgets_1.5.2 ## [82] tidyselect_1.1.0 processx_3.4.5 plyr_1.8.6 ## [85] magrittr_2.0.1 bookdown_0.21 R6_2.5.0 ## [88] generics_0.1.0 DBI_1.1.0 mgcv_1.8-33 ## [91] pillar_1.4.7 haven_2.3.1 withr_2.3.0 ## [94] xts_0.12.1 survival_3.2-7 modelr_0.1.8 ## [97] crayon_1.3.4 rmarkdown_2.5 grid_4.0.3 ## [100] readxl_1.3.1 callr_3.5.1 threejs_0.3.3 ## [103] reprex_0.3.0 digest_0.6.27 webshot_0.5.2 ## [106] xtable_1.8-4 httpuv_1.5.4 RcppParallel_5.0.2 ## [109] stats4_4.0.3 munsell_0.5.0 viridisLite_0.3.0 ## [112] shinyjs_2.0.0 References "],["rethinking.html", "Chapter 3 rethinking 3.1 Resources 3.2 Description 3.3 Environment Setup 3.4 Linear Model 3.5 Semi-parametric Model 3.6 Session Info", " Chapter 3 rethinking 3.1 Resources Statistical Rethinking by McElreath Statistical Rethinking Lectures on YouTube rethinking github repo 3.2 Description Statistical Rethinking was one of the first books I read on Bayesian methods, and I highly recommend it. McElreath uses a lot of practical examples which I found very helpful. All of the problems in the book are done with the rethinking package which uses the familiar formula syntax for defining models. However, unlike rstanarm the functions are not close mirrors of familiar frequentist functions. Another difference from rstanarm is you must specify all priors–there are no defaults. The rethinking package has some nice extras. One is the stancode function which returns the stan code generated for the model. This is a great way to start getting familiar with stan syntax! Second map2stan returns an object that contains a stanfit object which you can access with the @stanfit accessor. Most of the bayesplot and shinystan functions work with that stanfit object. Alternatively, the rethinking package includes its own functions that work directly on the returned map2stan object (see the book for details). I ran into some difficulty with the semi-parametric regression (3.5), but aside from that the rethinking package is also a very good option for getting started. 3.3 Environment Setup set.seed(123) options(&quot;scipen&quot; = 1, &quot;digits&quot; = 4) library(tidyverse) library(datasets) data(mtcars) # mean center disp predictor mtcars$c_disp = mtcars$disp - mean(mtcars$disp) library(rethinking) library(bayesplot) # Saves compiled version of model so it only has to be recompiled if the model is changed rstan_options(auto_write = TRUE) # Set number of cores options(mc.cores = parallel::detectCores()) 3.4 Linear Model 3.4.1 Define Model The rethinking package does not have default priors so I need to explicitly choose them. Again I’ll use the following model: \\[\\begin{align*} mpg &amp;\\sim Normal(\\mu, \\sigma^2) \\\\ \\mu &amp;= a + b*c\\_disp \\\\ a &amp;\\sim Normal(13.2, 5.3^2) \\\\ b &amp;\\sim Normal(-0.1, 0.05^2) \\\\ \\sigma &amp;\\sim Exponential(1) \\end{align*}\\] # Note the sign change for mu and b, this seems to be a quirk # of map2stan that it didn&#39;t like b ~ dnorm(-0.1, 0.05) f &lt;- alist( mpg ~ dnorm(mu, sigma), mu &lt;- a - b * c_disp, a ~ dnorm(13.2, 5.3), b ~ dnorm(0.1, 0.05), sigma ~ dexp(1) ) # Note the default number of chains = 1, so I&#39;m explicitly setting to available cores mdl1 &lt;- map2stan(f,mtcars, chains=parallel::detectCores()) The automatically generated stan code: stancode(mdl1) ## //2021-01-02 17:34:08 ## data{ ## int&lt;lower=1&gt; N; ## real mpg[N]; ## real c_disp[N]; ## } ## parameters{ ## real a; ## real b; ## real&lt;lower=0&gt; sigma; ## } ## model{ ## vector[N] mu; ## sigma ~ exponential( 1 ); ## b ~ normal( 0.1 , 0.05 ); ## a ~ normal( 13.2 , 5.3 ); ## for ( i in 1:N ) { ## mu[i] = a - b * c_disp[i]; ## } ## mpg ~ normal( mu , sigma ); ## } ## generated quantities{ ## vector[N] mu; ## for ( i in 1:N ) { ## mu[i] = a - b * c_disp[i]; ## } ## } 3.4.2 Prior Predictive Distribution # Plot prior predictive distribution N &lt;- 50 prior_samples &lt;- as.data.frame(extract.prior(mdl1, n=N)) D &lt;- seq(min(mtcars$c_disp), max(mtcars$c_disp), length.out = N) res &lt;- as.data.frame(apply(prior_samples, 1, function(x) x[1] - x[2] * (D))) %&gt;% mutate(c_disp = D) %&gt;% pivot_longer(cols=c(-&quot;c_disp&quot;), names_to=&quot;iter&quot;) res %&gt;% ggplot() + geom_line(aes(x=c_disp, y=value, group=iter), alpha=0.2) + labs(x=&quot;c_disp&quot;, y=&quot;mpg&quot;) 3.4.3 Diagnostics mcmc_trace(mdl1@stanfit, pars=c(&quot;a&quot;, &quot;b&quot;, &quot;sigma&quot;)) mcmc_rank_overlay(mdl1@stanfit, pars=c(&quot;a&quot;, &quot;b&quot;, &quot;sigma&quot;)) The precis function displays n_eff and \\(\\widehat{R}\\). precis(mdl1, prob=0.95) ## mean sd 2.5% 97.5% n_eff Rhat4 ## a 20.01656 0.560896 18.90335 21.12146 3632 0.9997 ## b 0.04187 0.004546 0.03313 0.05089 4100 1.0005 ## sigma 3.21625 0.403185 2.54299 4.10568 3085 1.0017 3.4.4 Posterior Distribution The precis function above also displays both the posterior point estimate and credible interval. 3.4.5 Posterior Predictive Distribution Finally, I’ll check the posterior predictive distribution. The rethinking package includes the postcheck function which displays a plot for posterior predictive checking. postcheck(mdl1, window=nrow(mtcars)) Personally, I find the postcheck plot hard to use because I can never remember what the different symbols represent. I prefer the density overlay plot as shown below. ppc_dens_overlay(mtcars$mpg, sim(mdl1, n=50)) ## [ 5 / 50 ] [ 10 / 50 ] [ 15 / 50 ] [ 20 / 50 ] [ 25 / 50 ] [ 30 / 50 ] [ 35 / 50 ] [ 40 / 50 ] [ 45 / 50 ] [ 50 / 50 ] And the expectation of the posterior predictive distribution (i.e., \\(\\mu\\)) like I did with rstanarm can be generated via the link function. newdata &lt;- data.frame(c_disp=seq(min(mtcars$c_disp), max(mtcars$c_disp))) y_rep &lt;- as.data.frame(t(link(mdl1, data=newdata, n=50))) %&gt;% cbind(newdata) %&gt;% pivot_longer(-c_disp, names_to=&quot;draw&quot;, values_to=&quot;mpg&quot;) y_rep %&gt;% ggplot(aes(x=c_disp, y=mpg)) + geom_line(aes(group=draw), alpha=0.2) + geom_point(data = mtcars) 3.5 Semi-parametric Model 3.5.1 Define Model Setting up the semi-parametric model is a bit more work in the rethinking package. First, I explicitly create the splines. The component splines are plotted below. library(splines) num_knots &lt;- 4 # number of interior knots knot_list &lt;- quantile(mtcars$c_disp, probs=seq(0,1,length.out = num_knots)) B &lt;- bs(mtcars$c_disp, knots=knot_list[-c(1,num_knots)], intercept=TRUE) df1 &lt;- cbind(c_disp=mtcars$c_disp, B) %&gt;% as.data.frame() %&gt;% pivot_longer(-c_disp, names_to=&quot;spline&quot;, values_to=&quot;val&quot;) # Plot at smaller intervals so curves are smooth N&lt;- 50 D &lt;- seq(min(mtcars$c_disp), max(mtcars$c_disp), length.out = N) B_plot &lt;- bs(D, knots=knot_list[-c(1,num_knots)], intercept=TRUE) df2 &lt;- cbind(c_disp=D, B_plot) %&gt;% as.data.frame() %&gt;% pivot_longer(-c_disp, names_to=&quot;spline&quot;, values_to=&quot;val&quot;) ggplot(mapping=aes(x=c_disp, y=val, color=spline)) + geom_point(data=df1) + geom_line(data=df2, linetype=&quot;dashed&quot;) Note: the dashed lines are the splines and the points are the values of the spline at the specific values of mtcars$c_disp; the points are inputs into the rethinking model. Then I define the model with the splines. I wasn’t able to get this model to work with either the map2stan or ulam functions, so I used quap instead which fits a quadratic approximation. f &lt;- alist( mpg ~ dnorm(mu, sigma), mu &lt;- a - B %*% w, a ~ dnorm(25, 10), w ~ dnorm(0,5), sigma ~ dexp(1) ) mdl2 &lt;- quap(f, data=list(mpg=mtcars$mpg, B=B), start=list(w=rep(1, ncol(B))) ) 3.5.2 Diagnostics Since MCMC was not used to fit the model, there are no chain diagnostics to examine. 3.5.3 Posterior Distribution I can still use the precis function to look at the posterior distribution, although there’s really no intuitive interpretation for the spline weights. precis(mdl2, depth=2) ## mean sd 5.5% 94.5% ## w[1] -12.0857 2.2957 -15.755 -8.4166 ## w[2] -4.3134 2.5531 -8.394 -0.2331 ## w[3] 0.4939 2.7405 -3.886 4.8738 ## w[4] 5.9012 2.8873 1.287 10.5157 ## w[5] 2.1850 2.8839 -2.424 6.7940 ## w[6] 9.0626 2.3915 5.241 12.8846 ## a 20.2067 2.0329 16.958 23.4556 ## sigma 1.9637 0.2397 1.581 2.3468 3.5.4 Posterior Predictive Distribution Finally, the posterior predictive distribution and LOESS for comparison: mu &lt;- link(mdl2) mu_mean &lt;- as.data.frame(apply(mu, 2, mean)) %&gt;% mutate(c_disp=mtcars$c_disp) colnames(mu_mean) &lt;- c(&quot;mpg_ppd&quot;, &quot;c_disp&quot;) mu_PI &lt;- as.data.frame(t(apply(mu,2,PI,0.95))) %&gt;% mutate(c_disp=mtcars$c_disp) colnames(mu_PI) &lt;- c(&quot;lwr&quot;, &quot;upr&quot;, &quot;c_disp&quot;) ggplot() + geom_point(data=mtcars, aes(x=c_disp, y=mpg)) + geom_line(data=mu_mean, aes(x=c_disp, y=mpg_ppd), color=&quot;blue&quot;) + geom_ribbon(data=mu_PI, aes(x=c_disp, ymin=lwr, ymax=upr), alpha=0.2) + labs(title=&quot;GAM&quot;) ggplot(mapping=aes(x=c_disp, y=mpg-mean(mpg)), data=mtcars) + geom_point()+ stat_smooth(method=&quot;loess&quot;, level=0.95) + labs(title=&quot;LOESS&quot;) 3.6 Session Info sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Big Sur 10.16 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] splines parallel stats graphics grDevices datasets utils ## [8] methods base ## ## other attached packages: ## [1] bayesplot_1.7.2 rethinking_2.13 rstan_2.21.2 ## [4] StanHeaders_2.21.0-6 forcats_0.5.0 stringr_1.4.0 ## [7] dplyr_1.0.2 purrr_0.3.4 readr_1.4.0 ## [10] tidyr_1.1.2 tibble_3.0.4 ggplot2_3.3.2 ## [13] tidyverse_1.3.0 ## ## loaded via a namespace (and not attached): ## [1] nlme_3.1-149 matrixStats_0.57.0 fs_1.5.0 lubridate_1.7.9.2 ## [5] httr_1.4.2 tools_4.0.3 backports_1.2.0 R6_2.5.0 ## [9] mgcv_1.8-33 DBI_1.1.0 colorspace_2.0-0 withr_2.3.0 ## [13] tidyselect_1.1.0 gridExtra_2.3 prettyunits_1.1.1 processx_3.4.5 ## [17] curl_4.3 compiler_4.0.3 cli_2.2.0 rvest_0.3.6 ## [21] xml2_1.3.2 labeling_0.4.2 bookdown_0.21 scales_1.1.1 ## [25] mvtnorm_1.1-1 ggridges_0.5.2 callr_3.5.1 digest_0.6.27 ## [29] rmarkdown_2.5 pkgconfig_2.0.3 htmltools_0.5.0 dbplyr_2.0.0 ## [33] rlang_0.4.9 readxl_1.3.1 rstudioapi_0.13 shape_1.4.5 ## [37] generics_0.1.0 farver_2.0.3 jsonlite_1.7.1 inline_0.3.17 ## [41] magrittr_2.0.1 loo_2.3.1 Matrix_1.2-18 Rcpp_1.0.5 ## [45] munsell_0.5.0 fansi_0.4.1 lifecycle_0.2.0 stringi_1.5.3 ## [49] yaml_2.2.1 MASS_7.3-53 pkgbuild_1.1.0 plyr_1.8.6 ## [53] grid_4.0.3 crayon_1.3.4 lattice_0.20-41 haven_2.3.1 ## [57] hms_0.5.3 knitr_1.30 ps_1.4.0 pillar_1.4.7 ## [61] reshape2_1.4.4 codetools_0.2-16 stats4_4.0.3 reprex_0.3.0 ## [65] glue_1.4.2 evaluate_0.14 V8_3.4.0 renv_0.12.0 ## [69] RcppParallel_5.0.2 modelr_0.1.8 vctrs_0.3.5 cellranger_1.1.0 ## [73] gtable_0.3.0 assertthat_0.2.1 xfun_0.19 broom_0.7.2 ## [77] coda_0.19-4 ellipsis_0.3.1 "],["brms.html", "Chapter 4 brms 4.1 Resources 4.2 Description 4.3 Environment Setup 4.4 Linear Model 4.5 Semi-parametric Model 4.6 Session Info", " Chapter 4 brms 4.1 Resources Overview of brms Solomon Kurz’s translation of Statistical Rethinking 4.2 Description For those familiar with the lme4 package, brms is a natural transition because it uses a similar syntax for specifying multi-level models. brms capabilities overlap in some areas with both rstanarm and rethinking while providing expanded features in other areas. For example, brms supports default priors (although not the same weakly informative priors as rstanarm) while also allowing great flexibility for user-defined priors (like rethinking). The brmsfit object is compatible with both the bayesplot and shinystan packages. Like rethinking, there is a method for extracting the automatically generated stan code. These are just a few of the similarities and differences; the overview document linked above includes a table with a complete comparison of the three packages. 4.3 Environment Setup set.seed(123) options(&quot;scipen&quot; = 1, &quot;digits&quot; = 4) knitr::opts_chunk$set(message=FALSE) library(tidyverse) library(datasets) data(mtcars) # mean center disp predictor mtcars$c_disp = mtcars$disp - mean(mtcars$disp) library(brms) library(bayesplot) # Set number of cores options(mc.cores = parallel::detectCores()) 4.4 Linear Model 4.4.1 Define Model The brms package default priors are improper flat priors over the real line. However, there is a strong case to be made against this type of non-informative prior.1 So I’ll proceed directly to the priors based on the EPA data. \\[\\begin{align*} mpg &amp;\\sim Normal(\\mu, \\sigma^2) \\\\ \\mu &amp;= a + b*c\\_disp \\\\ a &amp;\\sim Normal(13.2, 5.3^2) \\\\ b &amp;\\sim Normal(-0.1, 0.05^2) \\\\ \\sigma &amp;\\sim Exponential(1) \\end{align*}\\] mdl1 &lt;- brm(mpg ~ c_disp, data=mtcars, family=gaussian(), prior=c(set_prior(&quot;normal(-0.1, 0.05)&quot;, class=&quot;b&quot;, coef = &quot;c_disp&quot;), set_prior(&quot;normal(13.2, 5.3)&quot;, class=&quot;Intercept&quot;), set_prior(&quot;exponential(1)&quot;, class=&quot;sigma&quot;))) Like the rethinking package, brms also implements the stancode function. This stan model looks more complicated, but it is functionally equivalent to the rethinking model. stancode(mdl1) ## // generated with brms 2.14.4 ## functions { ## } ## data { ## int&lt;lower=1&gt; N; // total number of observations ## vector[N] Y; // response variable ## int&lt;lower=1&gt; K; // number of population-level effects ## matrix[N, K] X; // population-level design matrix ## int prior_only; // should the likelihood be ignored? ## } ## transformed data { ## int Kc = K - 1; ## matrix[N, Kc] Xc; // centered version of X without an intercept ## vector[Kc] means_X; // column means of X before centering ## for (i in 2:K) { ## means_X[i - 1] = mean(X[, i]); ## Xc[, i - 1] = X[, i] - means_X[i - 1]; ## } ## } ## parameters { ## vector[Kc] b; // population-level effects ## real Intercept; // temporary intercept for centered predictors ## real&lt;lower=0&gt; sigma; // residual SD ## } ## transformed parameters { ## } ## model { ## // likelihood including all constants ## if (!prior_only) { ## target += normal_id_glm_lpdf(Y | Xc, Intercept, b, sigma); ## } ## // priors including all constants ## target += normal_lpdf(b[1] | -0.1, 0.05); ## target += normal_lpdf(Intercept | 13.2, 5.3); ## target += exponential_lpdf(sigma | 1); ## } ## generated quantities { ## // actual population-level intercept ## real b_Intercept = Intercept - dot_product(means_X, b); ## } 4.4.2 Prior Predictive Distribution There are several methods for getting the prior predictive distribution from the brms model. The prior_summary function displays model priors. Manually draw samples from those distributions and then construct the prior predictive distribution as I did in 3.4.2. In the brm function, set the parameter sample_prior=\"yes\". Then use the function ’prior_samples` to get samples from the prior distributions and construct the prior predictive distribution. Sample from the model without conditioning on the data. We do that by setting the parameter sample_prior = \"only\" and then using the predict and/or posterior_epred functions to draw samples from the prior only model. Method 3 is demonstrated below. D &lt;- seq(min(mtcars$c_disp), max(mtcars$c_disp)) mdl1_prior &lt;- update(mdl1, sample_prior=&quot;only&quot;) # Samples from expected value of posterior predictive distribution eppd &lt;- posterior_epred(mdl1_prior, newdata=data.frame(c_disp=D), summary=FALSE, nsamples=50) %&gt;% t() %&gt;% as.data.frame() %&gt;% mutate(c_disp=D) %&gt;% pivot_longer(-c_disp, names_to=&quot;iter&quot;, values_to=&quot;mpg&quot;) ggplot() + geom_line(data=eppd, mapping=aes(x=c_disp, y=mpg, group=iter), alpha=0.2) 4.4.3 Diagnostics mcmc_rank_overlay(mdl1, pars=c(&quot;b_Intercept&quot;, &quot;b_c_disp&quot;, &quot;sigma&quot;)) summary(mdl1) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: mpg ~ c_disp ## Data: mtcars (Number of observations: 32) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 20.01 0.56 18.90 21.13 1.00 3358 2509 ## c_disp -0.04 0.00 -0.05 -0.03 1.00 4113 2720 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 3.21 0.40 2.56 4.14 1.00 3030 2442 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). 4.4.4 Posterior Distribution The fixef function extracts a summary of those population-level (i.e. fixed effect) parameters only, whereas the posterior_summary function summarizes the posterior draws for all model parameters. fixef(mdl1) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 20.01137 0.561868 18.90493 21.12712 ## c_disp -0.04156 0.004668 -0.05102 -0.03211 posterior_summary(mdl1) ## Estimate Est.Error Q2.5 Q97.5 ## b_Intercept 20.01137 0.561868 18.90493 21.12712 ## b_c_disp -0.04156 0.004668 -0.05102 -0.03211 ## sigma 3.21264 0.404501 2.55725 4.14268 ## lp__ -87.64601 1.291216 -90.98746 -86.22136 4.4.5 Posterior Predictive Distribution The brms package includes the pp_check function which uses bayesplot under the hood. # Equivalent to ppc_dens_overlay(mtcars$mpg, posterior_predict(mdl1, nsamples=50)) pp_check(mdl1, nsamples = 50) And below is a plot of the expected value of the posterior predictive distribution overlayed with the observations. D &lt;- seq(min(mtcars$c_disp), max(mtcars$c_disp)) # Samples from expected value of posterior predictive distribution eppd &lt;- posterior_epred(mdl1, newdata=data.frame(c_disp=D), nsamples=50, summary=FALSE) %&gt;% t() %&gt;% as.data.frame() %&gt;% mutate(c_disp=D) %&gt;% pivot_longer(-c_disp, names_to=&quot;iter&quot;, values_to=&quot;mpg&quot;) ggplot() + geom_line(data=eppd, mapping=aes(x=c_disp, y=mpg, group=iter), alpha=0.2) + geom_point(data=mtcars, mapping=aes(x=c_disp, y=mpg)) 4.5 Semi-parametric Model 4.5.1 Define Model The semi-parametric model is formulated as a mixed-model2 in brms. We can use the get_prior function to check what the default priors are for this mixed model. get_prior(mpg ~ s(c_disp, bs=&quot;cr&quot;, k=7), data=mtcars, family=gaussian()) ## prior class coef group resp dpar nlpar ## (flat) b ## (flat) b sc_disp_1 ## student_t(3, 19.2, 5.4) Intercept ## student_t(3, 0, 5.4) sds ## student_t(3, 0, 5.4) sds s(c_disp,bs=&quot;cr&quot;,k=7) ## student_t(3, 0, 5.4) sigma ## bound source ## default ## (vectorized) ## default ## default ## (vectorized) ## default I’ll replace the improper prior for the smoothing parameter fixed effect and leave the rest since they are weakly informative priors. See the set_prior help for details on changing the priors for the other parameters. mdl2 &lt;- brm(mpg ~ s(c_disp, bs=&quot;cr&quot;, k=7), data=mtcars, family=gaussian(), prior=c(set_prior(&quot;normal(0,5)&quot;, class=&quot;b&quot;)), control=list(adapt_delta=0.99)) ## Warning: There were 2 divergent transitions after warmup. See ## http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup ## to find out why this is a problem and how to eliminate them. ## Warning: Examine the pairs() plot to diagnose sampling problems 4.5.2 Prior Predictive Distribution mdl2_prior &lt;- update(mdl2, sample_prior=&quot;only&quot;) D &lt;- seq(min(mtcars$c_disp), max(mtcars$c_disp)) # Samples from expected value of posterior predictive distribution eppd &lt;- posterior_epred(mdl2_prior, newdata=data.frame(c_disp=D), summary=FALSE, nsamples=50) %&gt;% t() %&gt;% as.data.frame() %&gt;% mutate(c_disp=D) %&gt;% pivot_longer(-c_disp, names_to=&quot;iter&quot;, values_to=&quot;mpg&quot;) ggplot() + geom_line(data=eppd, mapping=aes(x=c_disp, y=mpg, group=iter), alpha=0.2) + geom_point(data=mtcars, mapping=aes(x=c_disp, y=mpg), color=&quot;blue&quot;) 4.5.3 Diagnostics summary(mdl2) ## Warning: There were 2 divergent transitions after warmup. Increasing adapt_delta ## above 0.99 may help. See http://mc-stan.org/misc/warnings.html#divergent- ## transitions-after-warmup ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: mpg ~ s(c_disp, bs = &quot;cr&quot;, k = 7) ## Data: mtcars (Number of observations: 32) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Smooth Terms: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sds(sc_disp_1) 1.42 0.88 0.42 3.66 1.00 881 1841 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 20.09 0.42 19.25 20.91 1.00 3566 2513 ## sc_disp_1 -3.18 0.27 -3.71 -2.65 1.00 2980 2679 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 2.41 0.35 1.83 3.22 1.00 2531 2312 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). pp_check(mdl2, nsamples=50) 4.5.4 Posterior Distribution The posterior_summary function summarizes the posterior samples for all of the model parameters. posterior_summary(mdl2) ## Estimate Est.Error Q2.5 Q97.5 ## b_Intercept 20.08637 0.4234 19.2513 20.9086 ## bs_sc_disp_1 -3.17969 0.2728 -3.7052 -2.6496 ## sds_sc_disp_1 1.41671 0.8788 0.4225 3.6582 ## sigma 2.40620 0.3547 1.8261 3.2163 ## s_sc_disp_1[1] 0.21932 1.4015 -2.6522 3.3024 ## s_sc_disp_1[2] 0.40156 0.1369 0.1261 0.6694 ## s_sc_disp_1[3] 1.21622 0.3535 0.5096 1.8888 ## s_sc_disp_1[4] 0.02512 0.5783 -1.1131 1.1811 ## s_sc_disp_1[5] -1.06316 1.1489 -3.5961 0.8077 ## lp__ -87.14421 2.7291 -93.3661 -82.6821 4.5.5 Posterior Predictive Distribution plot(conditional_effects(mdl2), points=TRUE) 4.6 Session Info sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Big Sur 10.16 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices datasets utils methods base ## ## other attached packages: ## [1] bayesplot_1.7.2 brms_2.14.4 Rcpp_1.0.5 forcats_0.5.0 ## [5] stringr_1.4.0 dplyr_1.0.2 purrr_0.3.4 readr_1.4.0 ## [9] tidyr_1.1.2 tibble_3.0.4 ggplot2_3.3.2 tidyverse_1.3.0 ## ## loaded via a namespace (and not attached): ## [1] minqa_1.2.4 colorspace_2.0-0 ellipsis_0.3.1 ## [4] ggridges_0.5.2 rsconnect_0.8.16 markdown_1.1 ## [7] base64enc_0.1-3 fs_1.5.0 rstudioapi_0.13 ## [10] farver_2.0.3 rstan_2.21.2 DT_0.16 ## [13] fansi_0.4.1 mvtnorm_1.1-1 lubridate_1.7.9.2 ## [16] xml2_1.3.2 codetools_0.2-16 bridgesampling_1.0-0 ## [19] splines_4.0.3 knitr_1.30 shinythemes_1.1.2 ## [22] projpred_2.0.2 jsonlite_1.7.1 nloptr_1.2.2.2 ## [25] broom_0.7.2 dbplyr_2.0.0 shiny_1.5.0 ## [28] compiler_4.0.3 httr_1.4.2 backports_1.2.0 ## [31] assertthat_0.2.1 Matrix_1.2-18 fastmap_1.0.1 ## [34] cli_2.2.0 later_1.1.0.1 prettyunits_1.1.1 ## [37] htmltools_0.5.0 tools_4.0.3 igraph_1.2.6 ## [40] coda_0.19-4 gtable_0.3.0 glue_1.4.2 ## [43] reshape2_1.4.4 V8_3.4.0 cellranger_1.1.0 ## [46] vctrs_0.3.5 nlme_3.1-149 crosstalk_1.1.0.1 ## [49] xfun_0.19 ps_1.4.0 lme4_1.1-26 ## [52] rvest_0.3.6 mime_0.9 miniUI_0.1.1.1 ## [55] lifecycle_0.2.0 renv_0.12.0 gtools_3.8.2 ## [58] statmod_1.4.35 MASS_7.3-53 zoo_1.8-8 ## [61] scales_1.1.1 colourpicker_1.1.0 hms_0.5.3 ## [64] promises_1.1.1 Brobdingnag_1.2-6 parallel_4.0.3 ## [67] inline_0.3.17 shinystan_2.5.0 curl_4.3 ## [70] gamm4_0.2-6 yaml_2.2.1 gridExtra_2.3 ## [73] StanHeaders_2.21.0-6 loo_2.3.1 stringi_1.5.3 ## [76] dygraphs_1.1.1.6 pkgbuild_1.1.0 boot_1.3-25 ## [79] rlang_0.4.9 pkgconfig_2.0.3 matrixStats_0.57.0 ## [82] evaluate_0.14 lattice_0.20-41 labeling_0.4.2 ## [85] rstantools_2.1.1 htmlwidgets_1.5.2 processx_3.4.5 ## [88] tidyselect_1.1.0 plyr_1.8.6 magrittr_2.0.1 ## [91] bookdown_0.21 R6_2.5.0 generics_0.1.0 ## [94] DBI_1.1.0 pillar_1.4.7 haven_2.3.1 ## [97] withr_2.3.0 mgcv_1.8-33 xts_0.12.1 ## [100] abind_1.4-5 modelr_0.1.8 crayon_1.3.4 ## [103] rmarkdown_2.5 grid_4.0.3 readxl_1.3.1 ## [106] callr_3.5.1 threejs_0.3.3 reprex_0.3.0 ## [109] digest_0.6.27 xtable_1.8-4 httpuv_1.5.4 ## [112] RcppParallel_5.0.2 stats4_4.0.3 munsell_0.5.0 ## [115] shinyjs_2.0.0 https://mc-stan.org/users/documentation/case-studies/weakly_informative_shapes.html↩︎ http://matt-wand.utsacademics.info/publicns/Wand03.pdf↩︎ "],["rstan.html", "Chapter 5 rstan 5.1 Resources 5.2 Description 5.3 Environment Setup 5.4 Linear Model 5.5 Semi-parametric Model 5.6 Semi-parametric Model (Random Walk Prior) 5.7 Session Info", " Chapter 5 rstan 5.1 Resources mc-stan online documentation 5.2 Description All of the packages in the previous chapters are running stan under the hood. One of the biggest advantages to using rstan (or cmdstanr) is you get the full power and flexibility of stan so you can build models that aren’t supported by the other packages. The tradeoff is the syntax is quite different which can be a challenge for those who are only familiar with R. 5.3 Environment Setup set.seed(123) options(&quot;scipen&quot; = 1, &quot;digits&quot; = 4) library(tidyverse) library(datasets) data(mtcars) # mean center disp predictor mtcars$c_disp = mtcars$disp - mean(mtcars$disp) library(rstan) library(bayesplot) # Saves compiled version of model so it only has to be recompiled if the model is changed rstan_options(auto_write = TRUE) # Set number of cores options(mc.cores = parallel::detectCores()) 5.4 Linear Model 5.4.1 Define Model Like the rethinking package, rstan doesn’t have default priors, so I need to explicitly choose them: \\[\\begin{align*} mpg &amp;\\sim Normal(\\mu, \\sigma^2) \\\\ \\mu &amp;= a + b*c\\_disp \\\\ a &amp;\\sim Normal(13.2, 5.3^2) \\\\ b &amp;\\sim Normal(-0.1, 0.05^2) \\\\ \\sigma &amp;\\sim Exponential(1) \\end{align*}\\] For a simple linear model there are three sections to the model definition: data - This is where the data structures for the known/observed portions of the model (e.g., the number of observations, the number and type of predictors) are defined. parameters - This is where the data structures for the parameters to be estimated are defined. For example, the coefficients of the simple linear model belong in this section. model - This is where the model (including priors) is defined using the data structures from the previous sections. # Define model mdl_code &lt;- &#39; data{ int&lt;lower=1&gt; N; vector[N] mpg; vector[N] c_disp; } parameters{ real a; real b; real&lt;lower=0.0&gt; sigma; } model{ // Likelihood mpg ~ normal(a + b * c_disp, sigma); // Priors a ~ normal(13.2, 5.3); b ~ normal(-0.1, 0.05); sigma ~ exponential(1); } &#39; A couple of comments about the model definition. For those only familiar with R, it may seem like a lot of extra “stuff” is going on in the data and parameters sections. This is because stan is written in C++ which is statically typed, unlike R and Python which are dynamically typed. Essentially what that means is you must define the type of any variable before you use it. The lower= (and upper= not shown in this example) options define bounds for a variable. The data is checked against the bounds which can detect errors pre-compilation. Generally, bounds are a good idea but aren’t required. Next, populate the data structures from the data section and save in a list. mdl_data &lt;- list(N = nrow(mtcars), mpg = mtcars$mpg, c_disp = mtcars$c_disp) And this is the call to fit the model. # Fit model mdl1 &lt;- stan(model_code=mdl_code, data=mdl_data, model_name=&quot;mdl1&quot;) ## Trying to compile a simple C file 5.4.2 Prior Predictive Distribution I could manually construct the prior predictive distribution like I did in 3.4.2. Instead I’ll have stan generate the prior predictive distribution which will be useful for more complex models. First, create another model with just the data and generated quantities section. The generated quantities section mirrors the model section except it is now drawing samples from the priors without conditioning on the observed data. Also, in the stan call set the sampling algorithm for fixed parameters. # Plot prior predictive distribution mdl_prior &lt;- &#39; data{ int&lt;lower=1&gt; N; vector[N] c_disp; } generated quantities{ real a_sim = normal_rng(13.2, 5.3); real b_sim = normal_rng(-0.1, 0.05); real sigma_sim = exponential_rng(1); vector[N] Y_hat = a_sim + b_sim * c_disp; real mpg_sim[N] = normal_rng(Y_hat, sigma_sim); } &#39; N&lt;- 50 D &lt;- seq(min(mtcars$c_disp), max(mtcars$c_disp), length.out = N) mdl_data_prior &lt;- list(N = N, c_disp=D) mdl_prior &lt;- stan(model_code=mdl_prior, data=mdl_data_prior, model_name=&quot;mdl_prior&quot;, chains=1, algorithm=&quot;Fixed_param&quot;) ## Trying to compile a simple C file draws &lt;- as.data.frame(mdl_prior) %&gt;% head(50) # Expected value prior predictive distribution from generated Y_hat exp_mpg_sim &lt;- draws %&gt;% select(starts_with(&quot;Y_hat&quot;)) %&gt;% t() %&gt;% as.data.frame() %&gt;% mutate(c_disp = D) %&gt;% pivot_longer(-c_disp, names_to=&quot;iter&quot;, values_to=&quot;mpg&quot;) # Alternative method: Expected value prior predictive distribution from a_sim and b_sim # exp_mpg_sim &lt;- apply(draws, 1, function(x) x[&quot;a_sim&quot;] + x[&quot;b_sim&quot;] * (D)) %&gt;% # as.data.frame() %&gt;% # mutate(c_disp = D) %&gt;% # pivot_longer(-c_disp, names_to=&quot;iter&quot;, values_to=&quot;mpg&quot;) ggplot() + geom_line(data=exp_mpg_sim, mapping=aes(x=c_disp, y=mpg, group=iter), alpha=0.2) 5.4.3 Diagnostics mcmc_rank_overlay(mdl1, pars=c(&quot;a&quot;, &quot;b&quot;, &quot;sigma&quot;)) print(mdl1) ## Inference for Stan model: mdl1. ## 4 chains, each with iter=2000; warmup=1000; thin=1; ## post-warmup draws per chain=1000, total post-warmup draws=4000. ## ## mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat ## a 20.01 0.01 0.57 18.88 19.64 20.02 20.40 21.12 2986 1 ## b -0.04 0.00 0.00 -0.05 -0.04 -0.04 -0.04 -0.03 3697 1 ## sigma 3.21 0.01 0.39 2.55 2.93 3.18 3.45 4.07 3023 1 ## lp__ -57.72 0.03 1.25 -61.03 -58.30 -57.39 -56.81 -56.30 1672 1 ## ## Samples were drawn using NUTS(diag_e) at Sat Jan 2 17:37:23 2021. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split chains (at ## convergence, Rhat=1). 5.4.4 Posterior Distribution The print function above displays information about the posterior distributions in addition to n_eff. Alternatively, the plot function provides a graphical display of the posterior distributions. plot(mdl1) ## ci_level: 0.8 (80% intervals) ## outer_level: 0.95 (95% intervals) 5.4.5 Posterior Predictive Distribution Using the posterior samples, I can plot the expected value of the posterior predictive distribution. N&lt;- 50 D &lt;- seq(min(mtcars$c_disp), max(mtcars$c_disp), length.out = N) draws &lt;- as.data.frame(mdl1) %&gt;% head(50) # Expected value posterior predictive distribution post_pred &lt;- apply(draws, 1, function(x) x[&quot;a&quot;] + x[&quot;b&quot;]*(D)) %&gt;% as.data.frame() %&gt;% mutate(c_disp = D) %&gt;% pivot_longer(-c_disp, names_to=&quot;iter&quot;, values_to=&quot;mpg&quot;) ggplot(mapping=aes(x=c_disp, y=mpg)) + geom_line(data=post_pred, mapping=aes(group=iter), alpha=0.2) + geom_point(data=mtcars) Note that the expected value of the ppd doesn’t include \\(\\sigma\\). An alternative is to have stan automatically generate samples from the posterior predictive distribution by adding a generated quantities section to the model (similar to what I did for the prior predictive distribution). # Define model mdl_code_ppd &lt;- &#39; data{ int&lt;lower=1&gt; N; vector[N] mpg; vector[N] c_disp; } parameters{ real a; real b; real&lt;lower=0.0&gt; sigma; } transformed parameters{ // Expected value of posterior predictive vector[N] Y_hat = a + b * c_disp; } model{ // Likelihood mpg ~ normal(Y_hat, sigma); // Priors a ~ normal(13.2, 5.3); b ~ normal(-0.1, 0.05); sigma ~ exponential(1); } generated quantities{ // Posterior Predictive real mpg_ppd[N] = normal_rng(Y_hat, sigma); } &#39; # Fit model mdl1_ppd &lt;- stan(model_code=mdl_code_ppd, data=mdl_data) ## Trying to compile a simple C file draws &lt;- as.data.frame(mdl1_ppd) # 95% credible interval for expected value of ppd Eppd &lt;- draws %&gt;% select(starts_with(&quot;Y_hat&quot;)) %&gt;% apply(2, function(x) quantile(x, probs=c(0.025, 0.5, 0.975))) %&gt;% t() %&gt;% as.data.frame() %&gt;% mutate(c_disp = mtcars$c_disp) # 95 credible interval for ppd ppd &lt;- draws %&gt;% select(starts_with(&quot;mpg_ppd&quot;)) %&gt;% apply(2, function(x) quantile(x, probs=c(0.025, 0.5, 0.975))) %&gt;% t() %&gt;% as.data.frame() %&gt;% mutate(c_disp=mdl_data$c_disp) ggplot() + geom_line(data=Eppd, mapping=aes(x=c_disp, y=`50%`)) + geom_ribbon(data=ppd, mapping=aes(x=c_disp, ymin=`2.5%`, ymax=`97.5%`), alpha=0.5, fill=&quot;lightblue&quot;) + geom_ribbon(data=Eppd, mapping=aes(x=c_disp, ymin=`2.5%`, ymax=`97.5%`), alpha=0.5, fill=&quot;dodgerblue&quot;) + geom_point(data=mtcars, mapping=aes(x=c_disp, y=mpg)) + labs(x=&quot;c_disp&quot;, y=&quot;mpg&quot;) The darker blue area is a 95% credible interval for the expected value of the posterior predictive distribution and the lighter blue area is the 95% credible interval for the posterior predictive distribution. And we can also plot the density overlay using the posterior predictive draws. yrep &lt;- draws %&gt;% head(50) %&gt;% select(starts_with(&quot;mpg_ppd&quot;)) %&gt;% as.matrix() ppc_dens_overlay(mtcars$mpg, yrep) 5.5 Semi-parametric Model 5.5.1 Define Model First, I’ll define the splines just as I did with the rethinking package. library(splines) num_knots &lt;- 4 # number of interior knots knot_list &lt;- quantile(mtcars$c_disp, probs=seq(0,1,length.out = num_knots)) B &lt;- bs(mtcars$c_disp, knots=knot_list[-c(1,num_knots)], intercept=TRUE) df1 &lt;- cbind(c_disp=mtcars$c_disp, B) %&gt;% as.data.frame() %&gt;% pivot_longer(-c_disp, names_to=&quot;spline&quot;, values_to=&quot;val&quot;) # Plot at smaller intervals so curves are smooth N&lt;- 50 D &lt;- seq(min(mtcars$c_disp), max(mtcars$c_disp), length.out = N) B_plot &lt;- bs(D, knots=knot_list[-c(1,num_knots)], intercept=TRUE) df2 &lt;- cbind(c_disp=D, B_plot) %&gt;% as.data.frame() %&gt;% pivot_longer(-c_disp, names_to=&quot;spline&quot;, values_to=&quot;val&quot;) ggplot(mapping=aes(x=c_disp, y=val, color=spline)) + geom_point(data=df1) + geom_line(data=df2, linetype=&quot;dashed&quot;) Note: the dashed lines are the splines and the points are the values of the spline at the specific values of mtcars$c_disp; the points are inputs into the stan model. # Define model mdl_code &lt;- &#39; data{ int&lt;lower=1&gt; N; int&lt;lower=1&gt; num_basis; vector[N] mpg; matrix[N, num_basis] B; } parameters{ real a; real&lt;lower=0.0&gt; sigma; vector[num_basis] w; } transformed parameters{ vector[N] Y_hat = a + B*w; } model{ // Likelihood mpg ~ normal(Y_hat, sigma); // Priors a ~ normal(25, 10); sigma ~ exponential(1); w ~ normal(0, 5); } generated quantities{ // Posterior Predictive real mpg_ppd[N] = normal_rng(Y_hat, sigma); } &#39; mdl_data &lt;- list(N=nrow(mtcars), num_basis=ncol(B), B=B, mpg = mtcars$mpg) # Fit model mdl1_gam &lt;- stan(model_code=mdl_code, data=mdl_data) ## Trying to compile a simple C file 5.5.2 Prior Predictive Distribution # Define model mdl2 &lt;- &#39; data{ int&lt;lower=1&gt; N; int&lt;lower=1&gt; num_basis; //vector[N] mpg; matrix[N, num_basis] B; } generated quantities{ real a_sim = normal_rng(25, 10); real sigma_sim = exponential_rng(1); real mpg_sim[N]; vector[N] Y_hat; vector[num_basis] w_sim; for (i in 1:num_basis) w_sim[i] = normal_rng(0,5); Y_hat = a_sim + B * w_sim; mpg_sim = normal_rng(Y_hat, sigma_sim); } &#39; mdl_gam_prior &lt;- stan(model_code=mdl2, data=list(N=nrow(B_plot), num_basis=ncol(B_plot), B=B_plot), chains=1, algorithm=&quot;Fixed_param&quot;) ## Trying to compile a simple C file draws &lt;- as.data.frame(mdl_gam_prior) %&gt;% head(50) exp_mpg_sim &lt;- draws %&gt;% select(starts_with(&quot;Y_hat&quot;)) %&gt;% t() %&gt;% as.data.frame() %&gt;% mutate(c_disp = D) %&gt;% pivot_longer(-c_disp, names_to=&quot;iter&quot;, values_to=&quot;mpg&quot;) ggplot() + geom_line(data=exp_mpg_sim, mapping=aes(x=c_disp, y=mpg, group=iter), alpha=0.2) 5.5.3 Diagnostics # Note that bayesplot methods support tidy selection of parameters mcmc_rank_overlay(mdl1_gam, pars=vars(a, sigma, starts_with(&quot;w[&quot;))) # This is the print.stanfit method and pars must be a character vector print(mdl1_gam, pars=c(&quot;a&quot;, &quot;sigma&quot;, &quot;w&quot;)) ## Inference for Stan model: 95f5b790b7449ad462398a31917fea97. ## 4 chains, each with iter=2000; warmup=1000; thin=1; ## post-warmup draws per chain=1000, total post-warmup draws=4000. ## ## mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat ## a 20.18 0.06 1.97 16.27 18.87 20.17 21.54 23.93 1252 1 ## sigma 2.23 0.01 0.30 1.71 2.02 2.20 2.41 2.92 2490 1 ## w[1] 11.94 0.06 2.34 7.32 10.36 11.91 13.52 16.52 1358 1 ## w[2] 4.36 0.06 2.57 -0.56 2.63 4.30 6.07 9.53 1956 1 ## w[3] -0.54 0.07 2.86 -6.13 -2.52 -0.49 1.40 5.04 1578 1 ## w[4] -5.69 0.07 2.91 -11.24 -7.63 -5.74 -3.73 0.08 1957 1 ## w[5] -2.30 0.07 2.92 -7.98 -4.28 -2.36 -0.41 3.55 1740 1 ## w[6] -8.82 0.06 2.42 -13.47 -10.48 -8.84 -7.19 -3.91 1639 1 ## ## Samples were drawn using NUTS(diag_e) at Sat Jan 2 17:39:22 2021. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split chains (at ## convergence, Rhat=1). 5.5.4 Posterior Distribution plot(mdl1_gam, pars=c(&quot;a&quot;, &quot;sigma&quot;, &quot;w&quot;)) ## ci_level: 0.8 (80% intervals) ## outer_level: 0.95 (95% intervals) 5.5.5 Posterior Predictive Distribution # 95% credible interval expected value of posterior predictive Eppd &lt;- as.data.frame(mdl1_gam) %&gt;% select(starts_with(&quot;Y_hat&quot;)) %&gt;% apply(2, function(x) quantile(x, probs=c(0.025, 0.5, 0.975))) %&gt;% t() %&gt;% as.data.frame() %&gt;% mutate(c_disp = mtcars$c_disp) # 95% credible interval posterior predictive ppd &lt;- as.data.frame(mdl1_gam) %&gt;% select(starts_with(&quot;mpg&quot;)) %&gt;% apply(2, function(x) quantile(x, probs=c(0.025, 0.5, 0.975))) %&gt;% t() %&gt;% as.data.frame() %&gt;% mutate(c_disp = mtcars$c_disp) ggplot() + geom_line(data=Eppd, mapping=aes(x=c_disp, y=`50%`)) + geom_ribbon(data=ppd, mapping=aes(x=c_disp, ymin=`2.5%`, ymax=`97.5%`), alpha=0.5, fill=&quot;lightblue&quot;) + geom_ribbon(data=Eppd, mapping=aes(x=c_disp, ymin=`2.5%`, ymax=`97.5%`), alpha=0.5, fill=&quot;dodgerblue&quot;) + geom_point(data=mtcars, mapping=aes(x=c_disp, y=mpg)) + labs(x=&quot;c_disp&quot;, y=&quot;mpg&quot;) 5.6 Semi-parametric Model (Random Walk Prior) 5.6.1 Define Model One challenge with splines is choosing the number of knots. For the previous model, I tried several values for num_knots until settling on 4. However, there is a stan case study for splines that uses a novel prior which addresses this issue. The details are here. For this example, I will set num_knots=20 and then fit models with and without the random walk prior. This is an example where the rstan’s flexibility is an advantage because it would be difficult or impossible to specify the random walk prior in the other packages. library(splines) num_knots &lt;- 20 # number of interior knots knot_list &lt;- quantile(mtcars$c_disp, probs=seq(0,1,length.out = num_knots)) B &lt;- bs(mtcars$c_disp, knots=knot_list[-c(1,num_knots)], intercept=TRUE) # Define model with smoothing prior mdl_smooth_code &lt;- &#39; data{ int&lt;lower=1&gt; N; int&lt;lower=1&gt; num_basis; vector[N] mpg; matrix[N, num_basis] B; } parameters{ real a; real&lt;lower=0.0&gt; sigma; vector[num_basis] w_raw; real&lt;lower=0.0&gt; tau; } transformed parameters{ vector[num_basis] w; vector[N] Y_hat; w[1] = w_raw[1]; for (i in 2:num_basis) w[i] = w[i-1] + w_raw[i]*tau; Y_hat = a + B*w; } model{ // Likelihood mpg ~ normal(Y_hat, sigma); // Priors a ~ normal(25, 10); sigma ~ exponential(1); w_raw ~ normal(0, 1); tau ~ normal(0,1); } generated quantities{ real mpg_ppd[N] = normal_rng(a + B*w, sigma); } &#39; mdl_data &lt;- list(N=nrow(mtcars), num_basis=ncol(B), B=B, mpg = mtcars$mpg) # Fit model with smoothing prior mdl2_gam_smooth &lt;- stan(model_code=mdl_smooth_code, data=mdl_data, control=list(adapt_delta=0.99)) ## Trying to compile a simple C file # Fit model without smoothing prior mdl2_gam &lt;- stan(model_code = mdl_code, data=mdl_data, control=list(adapt_delta=0.99)) 5.6.2 Diagnostics mcmc_rank_overlay(mdl2_gam_smooth, pars=vars(&quot;a&quot;, &quot;sigma&quot;, starts_with(&quot;w[&quot;))) print(mdl2_gam_smooth, pars=c(&quot;a&quot;, &quot;sigma&quot;, &quot;w&quot;)) ## Inference for Stan model: 2e3abf0ef6bf631fb50d560f27cb244a. ## 4 chains, each with iter=2000; warmup=1000; thin=1; ## post-warmup draws per chain=1000, total post-warmup draws=4000. ## ## mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat ## a 32.03 0.03 1.95 28.10 30.75 32.01 33.36 35.78 3632 1 ## sigma 2.18 0.01 0.32 1.63 1.95 2.14 2.37 2.92 3204 1 ## w[1] 0.05 0.01 1.01 -2.02 -0.63 0.04 0.72 2.04 4812 1 ## w[2] -1.11 0.03 1.90 -4.91 -2.36 -1.09 0.10 2.68 4398 1 ## w[3] -2.26 0.03 2.13 -6.39 -3.66 -2.28 -0.89 1.94 4223 1 ## w[4] -3.57 0.04 2.33 -8.18 -5.15 -3.50 -2.00 0.87 4251 1 ## w[5] -6.01 0.04 2.37 -10.82 -7.61 -5.97 -4.37 -1.51 4281 1 ## w[6] -8.34 0.04 2.31 -12.82 -9.95 -8.36 -6.75 -3.85 3762 1 ## w[7] -9.18 0.04 2.46 -14.12 -10.82 -9.21 -7.54 -4.36 4127 1 ## w[8] -9.76 0.04 2.32 -14.24 -11.33 -9.75 -8.16 -5.19 4245 1 ## w[9] -10.52 0.04 2.31 -15.04 -12.05 -10.50 -8.99 -6.09 4096 1 ## w[10] -11.98 0.04 2.24 -16.33 -13.53 -12.00 -10.40 -7.62 3735 1 ## w[11] -12.93 0.04 2.50 -17.77 -14.58 -12.94 -11.24 -8.09 4162 1 ## w[12] -13.34 0.04 2.45 -18.21 -14.99 -13.35 -11.72 -8.50 4281 1 ## w[13] -13.85 0.03 2.30 -18.33 -15.44 -13.85 -12.33 -9.27 4361 1 ## w[14] -15.63 0.04 2.37 -20.20 -17.22 -15.66 -14.12 -10.94 3722 1 ## w[15] -16.39 0.04 2.40 -21.09 -18.01 -16.42 -14.74 -11.75 3900 1 ## w[16] -16.66 0.04 2.41 -21.42 -18.22 -16.69 -15.02 -11.97 3940 1 ## w[17] -16.72 0.04 2.35 -21.35 -18.26 -16.72 -15.16 -12.03 3813 1 ## w[18] -16.00 0.04 2.30 -20.53 -17.56 -15.94 -14.51 -11.49 4181 1 ## w[19] -15.87 0.04 2.46 -20.54 -17.54 -15.89 -14.22 -11.08 4303 1 ## w[20] -17.45 0.04 2.45 -22.35 -19.13 -17.45 -15.75 -12.67 4148 1 ## w[21] -19.58 0.04 2.55 -24.50 -21.26 -19.59 -17.89 -14.52 3525 1 ## w[22] -20.55 0.04 2.67 -25.78 -22.35 -20.60 -18.77 -15.21 3964 1 ## ## Samples were drawn using NUTS(diag_e) at Sat Jan 2 17:40:26 2021. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split chains (at ## convergence, Rhat=1). 5.6.3 Posterior Distribution plot(mdl2_gam_smooth, pars=c(&quot;a&quot;, &quot;sigma&quot;, &quot;w&quot;)) plot(mdl2_gam, pars=c(&quot;a&quot;, &quot;sigma&quot;, &quot;w&quot;)) 5.6.4 Posterior Predictive Distribution # Draws from regular gam Epost_pred &lt;- as.data.frame(mdl2_gam) %&gt;% select(starts_with(&quot;Y_hat&quot;)) %&gt;% apply(2, function(x) quantile(x, probs=c(0.055, 0.5, 0.945))) %&gt;% t() %&gt;% as.data.frame() %&gt;% mutate(c_disp = mtcars$c_disp) # Draws from random walk model Epost_pred_smooth &lt;- as.data.frame(mdl2_gam_smooth) %&gt;% select(starts_with(&quot;Y_hat&quot;)) %&gt;% apply(2, function(x) quantile(x, probs=c(0.055, 0.5, 0.945))) %&gt;% t() %&gt;% as.data.frame() %&gt;% mutate(c_disp = mtcars$c_disp) rbind(Epost_pred %&gt;% select(c(&quot;c_disp&quot;, `50%`)) %&gt;% mutate(type=&quot;without smoothing prior&quot;), Epost_pred_smooth %&gt;% select(c(&quot;c_disp&quot;, `50%`)) %&gt;% mutate(type=&quot;with smoothing prior&quot;)) %&gt;% ggplot() + geom_line( mapping=aes(x=c_disp, y=`50%`, linetype=type), color=&quot;blue&quot; ) + geom_point(data=mtcars, mapping=aes(x=c_disp, y=mpg)) + labs(y=&quot;mpg&quot;) The plot above shows that even with a large number of knots (in this case 20), the model with the smoothing prior significantly reduces over-fitting when compared to the model without the smoothing prior. 5.7 Session Info sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Big Sur 10.16 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] splines stats graphics grDevices datasets utils methods ## [8] base ## ## other attached packages: ## [1] bayesplot_1.7.2 rstan_2.21.2 StanHeaders_2.21.0-6 ## [4] forcats_0.5.0 stringr_1.4.0 dplyr_1.0.2 ## [7] purrr_0.3.4 readr_1.4.0 tidyr_1.1.2 ## [10] tibble_3.0.4 ggplot2_3.3.2 tidyverse_1.3.0 ## ## loaded via a namespace (and not attached): ## [1] httr_1.4.2 jsonlite_1.7.1 modelr_0.1.8 RcppParallel_5.0.2 ## [5] assertthat_0.2.1 stats4_4.0.3 renv_0.12.0 cellranger_1.1.0 ## [9] yaml_2.2.1 pillar_1.4.7 backports_1.2.0 glue_1.4.2 ## [13] digest_0.6.27 rvest_0.3.6 colorspace_2.0-0 htmltools_0.5.0 ## [17] plyr_1.8.6 pkgconfig_2.0.3 broom_0.7.2 haven_2.3.1 ## [21] bookdown_0.21 scales_1.1.1 processx_3.4.5 farver_2.0.3 ## [25] generics_0.1.0 ellipsis_0.3.1 withr_2.3.0 cli_2.2.0 ## [29] magrittr_2.0.1 crayon_1.3.4 readxl_1.3.1 evaluate_0.14 ## [33] ps_1.4.0 fs_1.5.0 fansi_0.4.1 xml2_1.3.2 ## [37] pkgbuild_1.1.0 tools_4.0.3 loo_2.3.1 prettyunits_1.1.1 ## [41] hms_0.5.3 lifecycle_0.2.0 matrixStats_0.57.0 V8_3.4.0 ## [45] munsell_0.5.0 reprex_0.3.0 callr_3.5.1 compiler_4.0.3 ## [49] rlang_0.4.9 grid_4.0.3 ggridges_0.5.2 rstudioapi_0.13 ## [53] labeling_0.4.2 rmarkdown_2.5 gtable_0.3.0 codetools_0.2-16 ## [57] inline_0.3.17 DBI_1.1.0 curl_4.3 reshape2_1.4.4 ## [61] R6_2.5.0 gridExtra_2.3 lubridate_1.7.9.2 knitr_1.30 ## [65] stringi_1.5.3 parallel_4.0.3 Rcpp_1.0.5 vctrs_0.3.5 ## [69] dbplyr_2.0.0 tidyselect_1.1.0 xfun_0.19 "],["references.html", "References", " References "]]
