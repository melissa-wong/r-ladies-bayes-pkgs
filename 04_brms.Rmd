
# brms {#brms}

## Resources

- [Overview of brms](https://cran.r-project.org/web/packages/brms/vignettes/brms_overview.pdf)

- [Solomon Kurz's translation of _Statistical Rethinking_](https://bookdown.org/content/4857/)

## Description

For those familiar with the `lme4` package, `brms` is a natural transition because it uses a similar syntax for specifying multi-level models. `brms` capabilities overlap in some areas with both `rstanarm` and `rethinking` while providing expanded features in other areas. For example, `brms` supports default priors (although not the same weakly informative priors as `rstanarm`) while also allowing great flexibility for user-defined priors (like `rethinking`). The `brmsfit` object is compatible with both the `bayesplot` and `shinystan` packages. Like `rethinking`, there is a method for extracting the automatically generated `stan` code. These are just a few of the similarities and differences; the overview document linked above includes a table with a complete comparison of the three packages.

## Environment Setup

```{r setup, results="hide", message=FALSE}

set.seed(123)
options("scipen" = 1, "digits" = 4)
knitr::opts_chunk$set(message=FALSE)

library(tidyverse)
library(datasets)
data(mtcars)
# mean center disp predictor
mtcars$c_disp = mtcars$disp - mean(mtcars$disp)

library(brms)
library(bayesplot)

# Set number of cores
options(mc.cores = parallel::detectCores())
```

## Linear Model

### Define Model

The `brms` package default priors are improper flat priors over the real line. However, there is a strong case to be made against this type of non-informative prior ^[https://mc-stan.org/users/documentation/case-studies/weakly_informative_shapes.html]. So I'll proceed directly to the priors based on the EPA data.

\begin{align*}
  mpg &\sim Normal(\mu, \sigma^2) \\
  \mu &= a + b*c\_disp \\
  a &\sim Normal(13.2, 5.3^2) \\
  b &\sim Normal(-0.1, 0.05^2) \\
  \sigma &\sim Exponential(1)
\end{align*}

```{r mdl1, results="hide"}

mdl1 <- brm(mpg ~ c_disp, data=mtcars, family=gaussian(), 
            prior=c(set_prior("normal(-0.1, 0.05)", class="b", coef = "c_disp"),
                    set_prior("normal(13.2, 5.3)", class="Intercept"),
                    set_prior("exponential(1)", class="sigma")))

```

Like the `rethinking` package, `brms` also implements the `stancode` function.  This `stan` model looks more complicated, but it is functionally equivalent to the `rethinking` model.

```{r mdl1_stancode}
stancode(mdl1)
```


### Prior Predictive Distribution

There are several methods for getting the prior predictive distribution from the `brms` model.

1. The `prior_summary` function displays model priors. Manually draw samples from those distributions and then construct the prior predictive distribution as I did in \@ref(rethinkingprior). 
    
2. In the `brm` function, set the parameter `sample_prior="yes"`.  Then use the function 'prior_samples` to get samples from the prior distributions and construct the prior predictive distribution.
    
3. Sample from the model _without_ conditioning on the data.  We do that by setting the parameter `sample_prior = "only"` and then using the `predict` and `posterior_epred` functions to draw samples from the prior only model.
    
Method 3 is demonstrated below.

```{r mdl1_prior, results="hide"}

D <- seq(min(mtcars$c_disp), max(mtcars$c_disp))

mdl1_prior <- update(mdl1, sample_prior="only")

# Summarizes samples from posterior predictive distribution
ppd <- as.data.frame(predict(mdl1_prior, newdata=data.frame(c_disp=D)))
# Samples from expected value of posterior predictive distribution
eppd <- posterior_epred(mdl1_prior, newdata=data.frame(c_disp=D), 
                        summary=FALSE, nsamples=50) %>%
  t() %>%
  as.data.frame() %>%
  mutate(c_disp=D) %>%
  pivot_longer(-c_disp, names_to="iter", values_to="mpg")


ggplot() +
  geom_ribbon(data=ppd, mapping=aes(x=D, ymin=Q2.5, ymax=Q97.5), alpha=0.5, fill="lightblue") +
  geom_line(data=eppd, mapping=aes(x=c_disp, y=mpg, group=iter), alpha=0.2) 
```


### Diagnostics

```{r mdl1_trankplot}
mcmc_rank_overlay(mdl1, pars=c("b_Intercept", "b_c_disp", "sigma"))
```

```{r mdl1_summary}
summary(mdl1)
```

### Posterior Distribution

The simple linear model only has population-level (i.e., "fixed") effects, and the `fixef` function extracts a summary of those parameters only.  Note that this is the same information as returned from the `summary` function above.

```{r mdl1_post}
fixef(mdl1)
```

### Posterior Predictive Distribution

The `brms` package includes the `pp_check` function which uses `bayesplot` under the hood.

```{r}
pp_check(mdl1, nsamples = 50)
```

Or we can use `ppc_dens_overly` directly with the `brmsfit` object as shown below.

```{r}
ppc_dens_overlay(mtcars$mpg, posterior_predict(mdl1, nsamples=50))
```


And below is a plot of the expected value of the posterior predictive distribution overlayed with the observations.

```{r mdl1_ppd, results="hide"}

D <- seq(min(mtcars$c_disp), max(mtcars$c_disp))

# Samples from expected value of posterior predictive distribution
eppd <- posterior_epred(mdl1, newdata=data.frame(c_disp=D), 
                        nsamples=50, summary=FALSE) %>%
  t() %>%
  as.data.frame() %>%
  mutate(c_disp=D) %>%
  pivot_longer(-c_disp, names_to="iter", values_to="mpg")


ggplot() +
  geom_line(data=eppd, mapping=aes(x=c_disp, y=mpg, group=iter), alpha=0.2) +
  geom_point(data=mtcars, mapping=aes(x=c_disp, y=mpg))
```

## Semi-parametric Model

### Define Model

The semi-parametric model is formulated as a mixed-model ^[http://matt-wand.utsacademics.info/publicns/Wand03.pdf] in `brms`.

We can use the `get_prior` function to check what the default priors are for this mixed model.

```{r}
get_prior(mpg ~ s(c_disp, bs="cr", k=7), data=mtcars, family=gaussian())
```
I'll replace the improper prior for the smoothing parameter fixed effect  and leave the rest since they are weakly informative priors.  See the `set_prior` help for details on changing the priors for the other parameters.

```{r mdl2, results="hide"}

mdl2 <- brm(mpg ~ s(c_disp, bs="cr", k=7), data=mtcars, family=gaussian(), 
            prior=c(set_prior("normal(0,5)", class="b")),
            control=list(adapt_delta=0.99))

```

### Prior Predictive Distribution

```{r mdl2_prior, results="hide"}

mdl2_prior <- update(mdl2, sample_prior="only")

pp_check(mdl2_prior, nsamples = 50)
```

### Diagnostics

```{r}
summary(mdl2)
```


```{r}
pp_check(mdl2, nsamples=50)
```


### Posterior Distribution

The summary
```{r}

```


### Posterior Predictive Distribution

```{r mdl2_ppd, fig.hold=TRUE, out.width="50%"}
plot(conditional_effects(mdl2), points=TRUE) 
```


## Session Info

```{r sessionInfo}
sessionInfo()
```

